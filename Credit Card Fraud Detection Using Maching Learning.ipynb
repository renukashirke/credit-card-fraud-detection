{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec561e5f",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Credit card fraud is a significant concern in the financial industry. It is essential for credit card companies to effectively identify and prevent fraudulent transactions to protect their customers from unauthorized charges. The primary objective of this project is to utilize credit card details to detect and prevent fraudulent transactions.\n",
    "\n",
    "## What is Credit Card Fraud?\n",
    "\n",
    "Credit card fraud occurs when someone illicitly uses your credit card number or a stolen physical card to make unauthorized financial transactions from your account without your knowledge or consent.\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "To conduct this analysis, we will use a real-world dataset available on Kaggle. This dataset contains credit card transactions made by European cardholders in September 2013. It provides a valuable resource for studying credit card fraud detection.\n",
    "\n",
    "### Dataset Details\n",
    "\n",
    "- The dataset covers transactions that took place over two days, including 492 fraudulent transactions out of a total of 284,807 transactions. It's important to note that this dataset is highly imbalanced, with fraudulent transactions accounting for only 0.172% of all transactions.\n",
    "\n",
    "- The dataset consists of numerical input variables derived from a Principal Component Analysis (PCA) transformation. Unfortunately, the original features and background information are not provided due to confidentiality constraints. \n",
    "\n",
    "- The features V1 through V28 represent the principal components obtained from the PCA. The 'Time' feature represents the seconds elapsed between each transaction and the first transaction in the dataset, while the 'Amount' feature denotes the transaction amount. The 'Class' feature serves as the response variable, taking a value of 1 in the case of fraud and 0 otherwise.\n",
    "\n",
    "This project aims to apply data analysis and machine learning techniques to identify patterns and anomalies in this dataset and develop a credit card fraud detection model.\n",
    "\n",
    "By leveraging this dataset, we can explore the features and apply various machine learning algorithms to improve fraud detection and minimize false positives, thus enhancing the security of credit card transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6304bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf405d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd409f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f8745",
   "metadata": {},
   "source": [
    "## Display the Top 5 Rows of the Dataset\n",
    "\n",
    "To view the first 5 rows of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f751dc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f023ac",
   "metadata": {},
   "source": [
    "## Check the Last 5 Rows of the Dataset\n",
    "\n",
    "To view the last 5 rows of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e45f432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>-1.593105</td>\n",
       "      <td>2.711941</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>4.626942</td>\n",
       "      <td>-0.924459</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>1.991691</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>-0.150189</td>\n",
       "      <td>0.915802</td>\n",
       "      <td>1.214756</td>\n",
       "      <td>-0.675143</td>\n",
       "      <td>1.164931</td>\n",
       "      <td>-0.711757</td>\n",
       "      <td>-0.025693</td>\n",
       "      <td>-1.221179</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>0.411614</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>-0.183699</td>\n",
       "      <td>-0.510602</td>\n",
       "      <td>1.329284</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>0.313502</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>-1.933849</td>\n",
       "      <td>-0.962886</td>\n",
       "      <td>-1.042082</td>\n",
       "      <td>0.449624</td>\n",
       "      <td>1.962563</td>\n",
       "      <td>-0.608577</td>\n",
       "      <td>0.509928</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>-1.040458</td>\n",
       "      <td>-0.031513</td>\n",
       "      <td>-0.188093</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.660377</td>\n",
       "      <td>0.167430</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9       V10       V11       V12  \\\n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  4.356170 -1.593105  2.711941   \n",
       "284803  1.058415  0.024330  0.294869  0.584800 -0.975926 -0.150189  0.915802   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454 -0.484782  0.411614  0.063119   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087 -0.399126 -1.933849 -0.962886   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180 -0.915427 -1.040458 -0.031513   \n",
       "\n",
       "             V13       V14       V15       V16       V17       V18       V19  \\\n",
       "284802 -0.689256  4.626942 -0.924459  1.107641  1.991691  0.510632 -0.682920   \n",
       "284803  1.214756 -0.675143  1.164931 -0.711757 -0.025693 -1.221179 -1.545556   \n",
       "284804 -0.183699 -0.510602  1.329284  0.140716  0.313502  0.395652 -0.577252   \n",
       "284805 -1.042082  0.449624  1.962563 -0.608577  0.509928  1.113981  2.897849   \n",
       "284806 -0.188093 -0.084316  0.041333 -0.302620 -0.660377  0.167430 -0.256117   \n",
       "\n",
       "             V20       V21       V22       V23       V24       V25       V26  \\\n",
       "284802  1.475829  0.213454  0.111864  1.014480 -0.509348  1.436807  0.250034   \n",
       "284803  0.059616  0.214205  0.924384  0.012463 -1.016226 -0.606624 -0.395255   \n",
       "284804  0.001396  0.232045  0.578229 -0.037501  0.640134  0.265745 -0.087371   \n",
       "284805  0.127434  0.265245  0.800049 -0.163298  0.123205 -0.569159  0.546668   \n",
       "284806  0.382948  0.261057  0.643078  0.376777  0.008797 -0.473649 -0.818267   \n",
       "\n",
       "             V27       V28  Amount  Class  \n",
       "284802  0.943651  0.823731    0.77      0  \n",
       "284803  0.068472 -0.053527   24.79      0  \n",
       "284804  0.004455 -0.026561   67.88      0  \n",
       "284805  0.108821  0.104533   10.00      0  \n",
       "284806 -0.002415  0.013649  217.00      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d03857",
   "metadata": {},
   "source": [
    "## Find the Shape of the Dataset\n",
    "\n",
    "To determine the number of rows and columns in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f50632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98cc0e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 284807\n",
      "Number of Columns: 31\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Rows:\", data.shape[0])\n",
    "print(\"Number of Columns:\", data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40a659",
   "metadata": {},
   "source": [
    "## Obtain Information about the Dataset\n",
    "\n",
    "To gather essential details about the dataset, including the total number of rows, total number of columns, datatypes of each column, and memory requirement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f529e6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07991a02",
   "metadata": {},
   "source": [
    "## Check for Null Values in the Dataset\n",
    "\n",
    "To identify if there are any missing (null) values in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e3a6c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ab7ca",
   "metadata": {},
   "source": [
    "Let's begin by displaying the first 5 rows of our dataset to get an initial overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c79e602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951561a",
   "metadata": {},
   "source": [
    "## Feature Scaling for 'Amount' Column\n",
    "\n",
    "As observed, most of the feature values in our dataset are within a similar range, except for the 'Amount' column. To ensure consistency and avoid any bias in our analysis, we will perform feature scaling specifically on the 'Amount' column.\n",
    "\n",
    "We will use the StandardScaler from the scikit-learn library for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df06acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8caaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "data['Amount'] = sc.fit_transform(pd.DataFrame(data['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15fc1eef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb56f660",
   "metadata": {},
   "source": [
    "The 'Amount' column is now standardized, bringing it to the same scale as the other features.\n",
    "\n",
    "## Removing the 'Time' Column\n",
    "\n",
    "At first glance, the 'Time' column may seem like an external deciding factor in our analysis. However, for our modeling process, we have decided to exclude it. \n",
    "\n",
    "We will proceed by removing the 'Time' column from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c49a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9aa80a",
   "metadata": {},
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83da8af8",
   "metadata": {},
   "source": [
    "## Checking for Duplicate Values\n",
    "\n",
    "Before proceeding further, let's check for duplicate values in our dataset. Initially, our dataset consisted of 284,807 transactions. \n",
    "\n",
    "To confirm the presence of duplicate transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712984e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b791f",
   "metadata": {},
   "source": [
    "If the output is True, it indicates the presence of duplicate values in our dataset.\n",
    "\n",
    "Now, let's proceed to remove the duplicates from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ef293fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f8a56",
   "metadata": {},
   "source": [
    "After removing duplicates, we can calculate the difference in the number of transactions to understand how many duplicates were removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d1ae6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "284807 - 275663"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74368830",
   "metadata": {},
   "source": [
    "As you can see, we successfully removed approximately 9,144 duplicate transactions. Our dataset is now free from duplicates, and we have also ensured that there are no missing values. We are ready to continue with our analysis.\n",
    "\n",
    "## Checking the Distribution of the Target Variable 'Class'\n",
    "\n",
    "Before proceeding, let's examine the distribution of our target variable 'Class' in our dataset. To see the count of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4786d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1       473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41dab3f",
   "metadata": {},
   "source": [
    "However, it's often better practice to visualize the distribution. For this purpose, we'll use the Seaborn library to create a count plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd0a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd3070ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ca295",
   "metadata": {},
   "source": [
    "As you can observe from the plot, our dataset is highly imbalanced. But what does an imbalanced dataset mean?\n",
    "\n",
    "### What Does an Imbalanced Dataset Mean?\n",
    "\n",
    "An imbalanced dataset refers to a type of dataset where the target class has an uneven distribution of observations. In our case, 'Class' represents the target variable, and it has two classes: one class with a very high number of observations (majority class) and the other with a very low number of observations (minority class).\n",
    "\n",
    "Here, the '1' class is considered the minority class, while the '0' class is the majority class.\n",
    "\n",
    "Let's explore the consequences of not handling an imbalanced dataset.\n",
    "\n",
    "## Storing Feature Matrix and Response (Target)\n",
    "\n",
    "To proceed with our analysis, we will create a feature matrix 'X' and a response vector 'y' from our dataset. The feature matrix 'X' will contain all the relevant features, while the response vector 'y' will hold the 'Class' variable, which is our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29b53b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed78c5a",
   "metadata": {},
   "source": [
    "## Splitting the Dataset into Training and Test Sets\n",
    "\n",
    "To evaluate the performance of our machine learning models, we will split our dataset into two distinct sets: one for training and one for testing. This allows us to train our models on one portion of the data and assess their performance on another, unseen portion.\n",
    "\n",
    "We will use the `train_test_split` function from scikit-learn to perform this split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cae5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1baa1e",
   "metadata": {},
   "source": [
    "With the provided code, we have successfully divided our dataset into two crucial sets:\n",
    "\n",
    "- **X_train** and **y_train**: These sets are designated for training our machine learning models. The features are stored in **X_train**, while the corresponding target variable, 'Class,' is stored in **y_train**. Our models will be trained on this data.\n",
    "\n",
    "- **X_test** and **y_test**: These sets are reserved for making predictions. We will utilize **X_test** as input for our models, generate predictions, and then compare these predictions with **y_test**. **y_test** contains our actual values, allowing us to assess the performance of our machine learning models.\n",
    "\n",
    "As previously noted, our dataset exhibits class imbalance. We will address this issue shortly by exploring oversampling and undersampling techniques. However, before doing so, let's first understand the consequences of not handling the imbalanced dataset.\n",
    "\n",
    "## Logistic Regression Model\n",
    "\n",
    "For our initial approach, we will use a logistic regression model. Since the target variable in our dataset contains categorical values (0 and 1), this is a binary classification problem. We'll employ various classification algorithms, and we'll begin with logistic regression.\n",
    "\n",
    "To train the logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd8e84a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87830c61",
   "metadata": {},
   "source": [
    "Now that our logistic regression model has been trained, we can use it to make predictions on our test set. Predictions are stored in the variable `y_pred1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10108251",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8daef8b",
   "metadata": {},
   "source": [
    "To assess the accuracy of our logistic regression model, we will use the `accuracy_score` metric from scikit-learn. The accuracy score compares the actual values (in `y_test`) with the predicted values (in `y_pred1`) generated by our model.\n",
    "\n",
    "To calculate the accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a499a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992200678359603"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de857412",
   "metadata": {},
   "source": [
    "As you've observed, the logistic regression model demonstrates an accuracy of approximately 99% on our dataset.\n",
    "To assess the precision, recall, and F1 score of our logistic regression model, we will use the respective metrics provided by scikit-learn. Each of these metrics takes both the actual values (in `y_test`) and the predicted values (in `y_pred1`) generated by our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8b6ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6644f787",
   "metadata": {},
   "source": [
    "To calculate the precision score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f45f9401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8870967741935484"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b45f3a",
   "metadata": {},
   "source": [
    "To calculate the recall score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "623c55ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6043956043956044"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f303dd",
   "metadata": {},
   "source": [
    "To calculate the F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e1c5122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.718954248366013"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e86d7",
   "metadata": {},
   "source": [
    "As observed, the precision, recall, and F1 scores are notably lower compared to accuracy. This discrepancy is primarily due to the imbalanced nature of our dataset. It is essential to consider precision, recall, and F1 score, especially when dealing with imbalanced datasets, as these metrics provide a more comprehensive assessment of model performance.\n",
    "\n",
    "## Handling the Imbalanced Dataset\n",
    "\n",
    "To address the issue of an imbalanced dataset, we can employ two primary techniques: undersampling and oversampling. In this section, we will start with undersampling, which involves randomly removing rows from the majority class to balance it with the minority class. This process helps prevent bias towards the majority class.\n",
    "\n",
    "### Undersampling Technique\n",
    "\n",
    "First, let's separate the normal and fraudulent transactions into two separate variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aee22cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = data[data['Class'] == 0]\n",
    "fraud = data[data['Class'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f8d2c6",
   "metadata": {},
   "source": [
    "We can determine the number of transactions in each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b5177a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275190, 30)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ab3ce",
   "metadata": {},
   "source": [
    "This shows the total number of normal transactions in our dataset. Similarly, we can check the number of fraudulent transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "725e7a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568cfa73",
   "metadata": {},
   "source": [
    "Now, let's perform undersampling by randomly selecting a subset of normal transactions to match the number of fraudulent transactions. We will select 473 random samples from the normal transactions to achieve this balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab646aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sample = normal.sample(n=473)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1195be55",
   "metadata": {},
   "source": [
    "The `normal_sample` variable comprises 473 randomly selected transactions from the normal category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78a1985b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa36e37",
   "metadata": {},
   "source": [
    "As observed, we have successfully performed undersampling, resulting in 473 normal transactions and 473 fraudulent transactions. To create a balanced dataset, we can concatenate these two subsets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a83f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.concat([normal_sample, fraud])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6db359",
   "metadata": {},
   "source": [
    "We have successfully merged the undersampled normal transactions and fraudulent transactions into the `new_data` variable. This action results in a balanced dataset that is now prepared for further analysis and modeling.\n",
    "\n",
    "To verify the distribution of the target variable 'Class' in our balanced dataset, we can utilize the `value_counts` function from the Pandas library. This function will display the count of each class in the 'Class' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "968fd577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    473\n",
       "1    473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d177349",
   "metadata": {},
   "source": [
    "Now that we have successfully balanced the dataset, let's take a look at the first few rows of our newly created `new_data` dataframe to get a sense of its structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caff4900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244830</th>\n",
       "      <td>1.862977</td>\n",
       "      <td>-0.786392</td>\n",
       "      <td>-0.058865</td>\n",
       "      <td>0.191037</td>\n",
       "      <td>-0.948697</td>\n",
       "      <td>0.193179</td>\n",
       "      <td>-1.072884</td>\n",
       "      <td>0.320416</td>\n",
       "      <td>1.284783</td>\n",
       "      <td>0.160609</td>\n",
       "      <td>0.634791</td>\n",
       "      <td>0.378870</td>\n",
       "      <td>-1.049264</td>\n",
       "      <td>0.102118</td>\n",
       "      <td>0.241635</td>\n",
       "      <td>0.935425</td>\n",
       "      <td>-0.827122</td>\n",
       "      <td>0.696004</td>\n",
       "      <td>-0.027752</td>\n",
       "      <td>-0.134366</td>\n",
       "      <td>0.091757</td>\n",
       "      <td>0.201352</td>\n",
       "      <td>0.328057</td>\n",
       "      <td>0.759735</td>\n",
       "      <td>-0.668731</td>\n",
       "      <td>0.425423</td>\n",
       "      <td>-0.035864</td>\n",
       "      <td>-0.036315</td>\n",
       "      <td>-0.161921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207724</th>\n",
       "      <td>0.165437</td>\n",
       "      <td>0.445860</td>\n",
       "      <td>-0.328321</td>\n",
       "      <td>0.192118</td>\n",
       "      <td>0.798749</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>0.596189</td>\n",
       "      <td>-0.050070</td>\n",
       "      <td>0.575519</td>\n",
       "      <td>-1.103317</td>\n",
       "      <td>-2.094682</td>\n",
       "      <td>-0.050325</td>\n",
       "      <td>0.519974</td>\n",
       "      <td>-1.868866</td>\n",
       "      <td>-1.410397</td>\n",
       "      <td>-0.180827</td>\n",
       "      <td>0.711295</td>\n",
       "      <td>0.634579</td>\n",
       "      <td>0.627574</td>\n",
       "      <td>0.056438</td>\n",
       "      <td>0.228709</td>\n",
       "      <td>1.045387</td>\n",
       "      <td>-0.291462</td>\n",
       "      <td>-0.986326</td>\n",
       "      <td>-0.185812</td>\n",
       "      <td>0.676513</td>\n",
       "      <td>0.123948</td>\n",
       "      <td>0.118457</td>\n",
       "      <td>-0.171996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155381</th>\n",
       "      <td>-0.419634</td>\n",
       "      <td>0.747052</td>\n",
       "      <td>0.382097</td>\n",
       "      <td>-0.608255</td>\n",
       "      <td>1.243116</td>\n",
       "      <td>-0.003526</td>\n",
       "      <td>0.674151</td>\n",
       "      <td>-0.008277</td>\n",
       "      <td>1.066342</td>\n",
       "      <td>-0.753224</td>\n",
       "      <td>1.036416</td>\n",
       "      <td>-1.732552</td>\n",
       "      <td>1.843924</td>\n",
       "      <td>1.457647</td>\n",
       "      <td>-2.509776</td>\n",
       "      <td>-0.299414</td>\n",
       "      <td>0.175916</td>\n",
       "      <td>0.484542</td>\n",
       "      <td>0.246246</td>\n",
       "      <td>0.055195</td>\n",
       "      <td>0.066396</td>\n",
       "      <td>0.702314</td>\n",
       "      <td>-0.335604</td>\n",
       "      <td>0.390440</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>0.606118</td>\n",
       "      <td>0.307896</td>\n",
       "      <td>0.207374</td>\n",
       "      <td>-0.350351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>-0.415426</td>\n",
       "      <td>0.673509</td>\n",
       "      <td>1.210091</td>\n",
       "      <td>-2.102860</td>\n",
       "      <td>0.137877</td>\n",
       "      <td>-1.294730</td>\n",
       "      <td>1.081153</td>\n",
       "      <td>-0.314013</td>\n",
       "      <td>0.546929</td>\n",
       "      <td>-0.983688</td>\n",
       "      <td>1.554804</td>\n",
       "      <td>1.026021</td>\n",
       "      <td>-0.251280</td>\n",
       "      <td>0.271507</td>\n",
       "      <td>0.158784</td>\n",
       "      <td>-0.448166</td>\n",
       "      <td>-0.751806</td>\n",
       "      <td>0.460596</td>\n",
       "      <td>0.110685</td>\n",
       "      <td>0.040063</td>\n",
       "      <td>0.126549</td>\n",
       "      <td>0.711798</td>\n",
       "      <td>-0.284272</td>\n",
       "      <td>0.543640</td>\n",
       "      <td>0.018714</td>\n",
       "      <td>-0.869842</td>\n",
       "      <td>0.235878</td>\n",
       "      <td>-0.021606</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138981</th>\n",
       "      <td>-0.825853</td>\n",
       "      <td>1.093659</td>\n",
       "      <td>1.207936</td>\n",
       "      <td>0.439296</td>\n",
       "      <td>-0.138087</td>\n",
       "      <td>-0.033251</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.554959</td>\n",
       "      <td>-1.003188</td>\n",
       "      <td>-0.221174</td>\n",
       "      <td>1.443746</td>\n",
       "      <td>0.866983</td>\n",
       "      <td>0.150603</td>\n",
       "      <td>0.751675</td>\n",
       "      <td>0.872862</td>\n",
       "      <td>-0.165548</td>\n",
       "      <td>0.140128</td>\n",
       "      <td>-0.144513</td>\n",
       "      <td>0.941286</td>\n",
       "      <td>-0.068484</td>\n",
       "      <td>-0.007313</td>\n",
       "      <td>-0.190885</td>\n",
       "      <td>0.151738</td>\n",
       "      <td>0.015689</td>\n",
       "      <td>-0.684919</td>\n",
       "      <td>0.169889</td>\n",
       "      <td>-0.124081</td>\n",
       "      <td>0.061329</td>\n",
       "      <td>-0.348072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "244830  1.862977 -0.786392 -0.058865  0.191037 -0.948697  0.193179 -1.072884   \n",
       "207724  0.165437  0.445860 -0.328321  0.192118  0.798749 -0.000433  0.596189   \n",
       "155381 -0.419634  0.747052  0.382097 -0.608255  1.243116 -0.003526  0.674151   \n",
       "3209   -0.415426  0.673509  1.210091 -2.102860  0.137877 -1.294730  1.081153   \n",
       "138981 -0.825853  1.093659  1.207936  0.439296 -0.138087 -0.033251  0.014841   \n",
       "\n",
       "              V8        V9       V10       V11       V12       V13       V14  \\\n",
       "244830  0.320416  1.284783  0.160609  0.634791  0.378870 -1.049264  0.102118   \n",
       "207724 -0.050070  0.575519 -1.103317 -2.094682 -0.050325  0.519974 -1.868866   \n",
       "155381 -0.008277  1.066342 -0.753224  1.036416 -1.732552  1.843924  1.457647   \n",
       "3209   -0.314013  0.546929 -0.983688  1.554804  1.026021 -0.251280  0.271507   \n",
       "138981  0.554959 -1.003188 -0.221174  1.443746  0.866983  0.150603  0.751675   \n",
       "\n",
       "             V15       V16       V17       V18       V19       V20       V21  \\\n",
       "244830  0.241635  0.935425 -0.827122  0.696004 -0.027752 -0.134366  0.091757   \n",
       "207724 -1.410397 -0.180827  0.711295  0.634579  0.627574  0.056438  0.228709   \n",
       "155381 -2.509776 -0.299414  0.175916  0.484542  0.246246  0.055195  0.066396   \n",
       "3209    0.158784 -0.448166 -0.751806  0.460596  0.110685  0.040063  0.126549   \n",
       "138981  0.872862 -0.165548  0.140128 -0.144513  0.941286 -0.068484 -0.007313   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "244830  0.201352  0.328057  0.759735 -0.668731  0.425423 -0.035864 -0.036315   \n",
       "207724  1.045387 -0.291462 -0.986326 -0.185812  0.676513  0.123948  0.118457   \n",
       "155381  0.702314 -0.335604  0.390440  0.009797  0.606118  0.307896  0.207374   \n",
       "3209    0.711798 -0.284272  0.543640  0.018714 -0.869842  0.235878 -0.021606   \n",
       "138981 -0.190885  0.151738  0.015689 -0.684919  0.169889 -0.124081  0.061329   \n",
       "\n",
       "          Amount  Class  \n",
       "244830 -0.161921      0  \n",
       "207724 -0.171996      0  \n",
       "155381 -0.350351      0  \n",
       "3209   -0.349231      0  \n",
       "138981 -0.348072      0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3199f",
   "metadata": {},
   "source": [
    "As observed, the `new_data` dataframe has random indexes. To ensure a consistent and sequential index, we can reset the indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3da77a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.concat([normal_sample, fraud], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3c8f3",
   "metadata": {},
   "source": [
    "This will reset the indexes in the `new_data` dataframe.\n",
    "\n",
    "Now, let's examine the distribution of the target variable 'Class' in the updated undersampled dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e411576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    473\n",
       "1    473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb279f0",
   "metadata": {},
   "source": [
    "Additionally, let's take another look at the first few rows of the `new_data` dataframe:\n",
    "\n",
    "This will display the initial content of the updated undersampled dataset with sequential indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b273f5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.862977</td>\n",
       "      <td>-0.786392</td>\n",
       "      <td>-0.058865</td>\n",
       "      <td>0.191037</td>\n",
       "      <td>-0.948697</td>\n",
       "      <td>0.193179</td>\n",
       "      <td>-1.072884</td>\n",
       "      <td>0.320416</td>\n",
       "      <td>1.284783</td>\n",
       "      <td>0.160609</td>\n",
       "      <td>0.634791</td>\n",
       "      <td>0.378870</td>\n",
       "      <td>-1.049264</td>\n",
       "      <td>0.102118</td>\n",
       "      <td>0.241635</td>\n",
       "      <td>0.935425</td>\n",
       "      <td>-0.827122</td>\n",
       "      <td>0.696004</td>\n",
       "      <td>-0.027752</td>\n",
       "      <td>-0.134366</td>\n",
       "      <td>0.091757</td>\n",
       "      <td>0.201352</td>\n",
       "      <td>0.328057</td>\n",
       "      <td>0.759735</td>\n",
       "      <td>-0.668731</td>\n",
       "      <td>0.425423</td>\n",
       "      <td>-0.035864</td>\n",
       "      <td>-0.036315</td>\n",
       "      <td>-0.161921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.165437</td>\n",
       "      <td>0.445860</td>\n",
       "      <td>-0.328321</td>\n",
       "      <td>0.192118</td>\n",
       "      <td>0.798749</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>0.596189</td>\n",
       "      <td>-0.050070</td>\n",
       "      <td>0.575519</td>\n",
       "      <td>-1.103317</td>\n",
       "      <td>-2.094682</td>\n",
       "      <td>-0.050325</td>\n",
       "      <td>0.519974</td>\n",
       "      <td>-1.868866</td>\n",
       "      <td>-1.410397</td>\n",
       "      <td>-0.180827</td>\n",
       "      <td>0.711295</td>\n",
       "      <td>0.634579</td>\n",
       "      <td>0.627574</td>\n",
       "      <td>0.056438</td>\n",
       "      <td>0.228709</td>\n",
       "      <td>1.045387</td>\n",
       "      <td>-0.291462</td>\n",
       "      <td>-0.986326</td>\n",
       "      <td>-0.185812</td>\n",
       "      <td>0.676513</td>\n",
       "      <td>0.123948</td>\n",
       "      <td>0.118457</td>\n",
       "      <td>-0.171996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.419634</td>\n",
       "      <td>0.747052</td>\n",
       "      <td>0.382097</td>\n",
       "      <td>-0.608255</td>\n",
       "      <td>1.243116</td>\n",
       "      <td>-0.003526</td>\n",
       "      <td>0.674151</td>\n",
       "      <td>-0.008277</td>\n",
       "      <td>1.066342</td>\n",
       "      <td>-0.753224</td>\n",
       "      <td>1.036416</td>\n",
       "      <td>-1.732552</td>\n",
       "      <td>1.843924</td>\n",
       "      <td>1.457647</td>\n",
       "      <td>-2.509776</td>\n",
       "      <td>-0.299414</td>\n",
       "      <td>0.175916</td>\n",
       "      <td>0.484542</td>\n",
       "      <td>0.246246</td>\n",
       "      <td>0.055195</td>\n",
       "      <td>0.066396</td>\n",
       "      <td>0.702314</td>\n",
       "      <td>-0.335604</td>\n",
       "      <td>0.390440</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>0.606118</td>\n",
       "      <td>0.307896</td>\n",
       "      <td>0.207374</td>\n",
       "      <td>-0.350351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.415426</td>\n",
       "      <td>0.673509</td>\n",
       "      <td>1.210091</td>\n",
       "      <td>-2.102860</td>\n",
       "      <td>0.137877</td>\n",
       "      <td>-1.294730</td>\n",
       "      <td>1.081153</td>\n",
       "      <td>-0.314013</td>\n",
       "      <td>0.546929</td>\n",
       "      <td>-0.983688</td>\n",
       "      <td>1.554804</td>\n",
       "      <td>1.026021</td>\n",
       "      <td>-0.251280</td>\n",
       "      <td>0.271507</td>\n",
       "      <td>0.158784</td>\n",
       "      <td>-0.448166</td>\n",
       "      <td>-0.751806</td>\n",
       "      <td>0.460596</td>\n",
       "      <td>0.110685</td>\n",
       "      <td>0.040063</td>\n",
       "      <td>0.126549</td>\n",
       "      <td>0.711798</td>\n",
       "      <td>-0.284272</td>\n",
       "      <td>0.543640</td>\n",
       "      <td>0.018714</td>\n",
       "      <td>-0.869842</td>\n",
       "      <td>0.235878</td>\n",
       "      <td>-0.021606</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.825853</td>\n",
       "      <td>1.093659</td>\n",
       "      <td>1.207936</td>\n",
       "      <td>0.439296</td>\n",
       "      <td>-0.138087</td>\n",
       "      <td>-0.033251</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.554959</td>\n",
       "      <td>-1.003188</td>\n",
       "      <td>-0.221174</td>\n",
       "      <td>1.443746</td>\n",
       "      <td>0.866983</td>\n",
       "      <td>0.150603</td>\n",
       "      <td>0.751675</td>\n",
       "      <td>0.872862</td>\n",
       "      <td>-0.165548</td>\n",
       "      <td>0.140128</td>\n",
       "      <td>-0.144513</td>\n",
       "      <td>0.941286</td>\n",
       "      <td>-0.068484</td>\n",
       "      <td>-0.007313</td>\n",
       "      <td>-0.190885</td>\n",
       "      <td>0.151738</td>\n",
       "      <td>0.015689</td>\n",
       "      <td>-0.684919</td>\n",
       "      <td>0.169889</td>\n",
       "      <td>-0.124081</td>\n",
       "      <td>0.061329</td>\n",
       "      <td>-0.348072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  1.862977 -0.786392 -0.058865  0.191037 -0.948697  0.193179 -1.072884   \n",
       "1  0.165437  0.445860 -0.328321  0.192118  0.798749 -0.000433  0.596189   \n",
       "2 -0.419634  0.747052  0.382097 -0.608255  1.243116 -0.003526  0.674151   \n",
       "3 -0.415426  0.673509  1.210091 -2.102860  0.137877 -1.294730  1.081153   \n",
       "4 -0.825853  1.093659  1.207936  0.439296 -0.138087 -0.033251  0.014841   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.320416  1.284783  0.160609  0.634791  0.378870 -1.049264  0.102118   \n",
       "1 -0.050070  0.575519 -1.103317 -2.094682 -0.050325  0.519974 -1.868866   \n",
       "2 -0.008277  1.066342 -0.753224  1.036416 -1.732552  1.843924  1.457647   \n",
       "3 -0.314013  0.546929 -0.983688  1.554804  1.026021 -0.251280  0.271507   \n",
       "4  0.554959 -1.003188 -0.221174  1.443746  0.866983  0.150603  0.751675   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  0.241635  0.935425 -0.827122  0.696004 -0.027752 -0.134366  0.091757   \n",
       "1 -1.410397 -0.180827  0.711295  0.634579  0.627574  0.056438  0.228709   \n",
       "2 -2.509776 -0.299414  0.175916  0.484542  0.246246  0.055195  0.066396   \n",
       "3  0.158784 -0.448166 -0.751806  0.460596  0.110685  0.040063  0.126549   \n",
       "4  0.872862 -0.165548  0.140128 -0.144513  0.941286 -0.068484 -0.007313   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.201352  0.328057  0.759735 -0.668731  0.425423 -0.035864 -0.036315   \n",
       "1  1.045387 -0.291462 -0.986326 -0.185812  0.676513  0.123948  0.118457   \n",
       "2  0.702314 -0.335604  0.390440  0.009797  0.606118  0.307896  0.207374   \n",
       "3  0.711798 -0.284272  0.543640  0.018714 -0.869842  0.235878 -0.021606   \n",
       "4 -0.190885  0.151738  0.015689 -0.684919  0.169889 -0.124081  0.061329   \n",
       "\n",
       "     Amount  Class  \n",
       "0 -0.161921      0  \n",
       "1 -0.171996      0  \n",
       "2 -0.350351      0  \n",
       "3 -0.349231      0  \n",
       "4 -0.348072      0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc636e",
   "metadata": {},
   "source": [
    "For the newly created dataset after undersampling, we need to store the feature matrix 'X' and the target variable 'y' for machine learning. These variables will enable us to train and evaluate our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fba12a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop('Class', axis=1)\n",
    "y = new_data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296156a4",
   "metadata": {},
   "source": [
    "With 'X' containing the features and 'y' holding the target variable, we can proceed to perform the train-test split, a crucial step that enables us to evaluate the performance of our machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0507646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eaaf3f",
   "metadata": {},
   "source": [
    "##  Logistic Regression Model After Undersampling\n",
    "\n",
    "Now that our dataset is prepared and balanced through undersampling, we are ready to execute our first machine learning algorithm, logistic regression. We will train a logistic regression model and proceed to evaluate its accuracy on the undersampled dataset.\n",
    "\n",
    "Let's train a logistic regression model and assess its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c8ac557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9105263157894737"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = logistic_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ccb3b",
   "metadata": {},
   "source": [
    "To calculate the precision score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3025b02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9207920792079208"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402797ea",
   "metadata": {},
   "source": [
    "To calculate the recall score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90936e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117647058823529"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe8e96",
   "metadata": {},
   "source": [
    "To calculate the F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccf2821d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9162561576354681"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620a8c47",
   "metadata": {},
   "source": [
    "As observed, all the evaluation scores have notably improved after undersampling the dataset. This highlights the importance of not relying solely on accuracy as a metric for unbalanced datasets. We must consider precision, recall, and F1 score to gain a more comprehensive understanding of model performance. This underscores the necessity of addressing imbalanced datasets.\n",
    "\n",
    "Now, let's proceed to use the Decision Tree Classifier on the undersampled dataset to further explore its performance.\n",
    "\n",
    "##  Decision Tree Classifier\n",
    "\n",
    "Let's assess the performance of the Decision Tree Classifier on the test set after applying SMOTE oversampling. We will calculate accuracy, precision, recall, and F1 score to evaluate the model's effectiveness.\n",
    "To make predictions using the Decision Tree Classifier, we start by fitting the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b254ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e116011",
   "metadata": {},
   "source": [
    "Having successfully trained the Decision Tree Classifier on our training set, we can now use it to make predictions on our unseen samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35c1d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e91976",
   "metadata": {},
   "source": [
    "The `y_pred2` variable contains the predictions generated by the Decision Tree Classifier.\n",
    "\n",
    "Let's evaluate the accuracy of the Decision Tree Classifier's predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a5f344c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210526315789473"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17571015",
   "metadata": {},
   "source": [
    "Let's assess the precision, recall, and F1 score of the predictions generated by the Decision Tree Classifier.\n",
    "To calculate the precision score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e001e762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9223300970873787"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1b34a9",
   "metadata": {},
   "source": [
    "Let's calculate the recall score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17f0f63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313725490196079"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a760f5",
   "metadata": {},
   "source": [
    "Now, we can compute the F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13d4232e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9268292682926829"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c38ad",
   "metadata": {},
   "source": [
    "##  Random Forest Classifier\n",
    "Let's proceed by training the Random Forest Classifier on the undersampled dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94845f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592aac6",
   "metadata": {},
   "source": [
    "With this code, we have successfully trained the Random Forest Classifier after undersampling.\n",
    "\n",
    "Let's assess the performance of the Random Forest Classifier on the test set. We'll evaluate accuracy, precision, recall, and F1 score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77008933",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8c27e1",
   "metadata": {},
   "source": [
    "The `y_pred3` variable contains the predictions made by the Random Forest Classifier.\n",
    "Let's calculate the accuracy of the Random Forest Classifier's predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10dfff21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9263157894736842"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfab841",
   "metadata": {},
   "source": [
    "To assess precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66fa1991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670c9c36",
   "metadata": {},
   "source": [
    "To calculate the recall score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3706fc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9019607843137255"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1ae07",
   "metadata": {},
   "source": [
    "Now, we can compute the F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc9998e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9292929292929293"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701b4a7",
   "metadata": {},
   "source": [
    "To provide a visual comparison of model performance, we can create a DataFrame that includes the accuracy scores of different models.\n",
    "\n",
    "To construct a DataFrame that summarizes the accuracy scores of three models: Logistic Regression (LR), Decision Tree Classifier (DT), and Random Forest Classifier (RF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9b21299",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame({'Models': ['LR', 'DT', 'RF'], 'ACC': [accuracy_score(y_test, y_pred1) * 100, accuracy_score(y_test, y_pred2) * 100, accuracy_score(y_test, y_pred3) * 100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a0cb4a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>91.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>92.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>92.631579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Models        ACC\n",
       "0     LR  91.052632\n",
       "1     DT  92.105263\n",
       "2     RF  92.631579"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d3c34b",
   "metadata": {},
   "source": [
    "To better understand and compare the performance of different models, we can create a bar plot that displays the accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3dce9a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Models', ylabel='ACC'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=final_data['Models'], y=final_data['ACC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d69d9",
   "metadata": {},
   "source": [
    "As depicted in the bar plot, it's evident that Logistic Regression is the best-performing model for this dataset after undersampling. This visualization underscores the effectiveness of undersampling in enhancing the model's performance and its significance in addressing imbalanced datasets.\n",
    "\n",
    "### Oversampling Technique\n",
    "\n",
    "While undersampling can lead to the loss of valuable data, we are now considering oversampling as an alternative solution. To counteract data imbalance, we will utilize SMOTE (Synthetic Minority Over-sampling Technique), one of the most commonly used oversampling methods.\n",
    "\n",
    "SMOTE's purpose is to balance class distribution by randomly increasing the number of minority class examples through the generation of synthetic data. Unlike duplication, SMOTE synthesizes new minority instances between existing minority instances. It accomplishes this by generating virtual training records through linear interpolation for the minority class. These synthetic data points are not duplicates but rather slightly different from the original data points.\n",
    "\n",
    "Now, let's implement SMOTE for oversampling. We will start by reloading our dataset, performing feature scaling, and removing the 'Time' column and duplicate values. As we are preparing the dataset for oversampling, we will store the feature matrix in 'X' and the response variable (target variable) in 'y'. We will also check the shapes of 'X' and 'y before applying SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7474227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd8f0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Amount'] = sc.fit_transform(pd.DataFrame(data['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea6b91af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c12d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1eeeb714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1       473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4df7a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89ac8846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 29)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77590815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62aa0e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ba529b",
   "metadata": {},
   "source": [
    "With the SMOTE library imported, we are ready to initiate the oversampling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58378b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = SMOTE().fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bfbe150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1    275190\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d37ea3a",
   "metadata": {},
   "source": [
    "As evident, we now have an equal number of samples for both normal and fraudulent transactions, thanks to SMOTE oversampling. This balanced dataset is ready for further analysis. Let's proceed with the train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b1540eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f9ab67",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Now that we have successfully applied SMOTE oversampling to address class imbalance, we can use logistic regression on the balanced dataset.\n",
    "\n",
    "Let's begin by training a logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3c5d38be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2988a",
   "metadata": {},
   "source": [
    "Let's assess the performance of logistic regression on the test set after applying SMOTE oversampling. We will calculate accuracy, precision, recall, and F1 score to gauge the model's effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f9ad26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5685f",
   "metadata": {},
   "source": [
    "The `y_pred1` variable contains the predictions made by the logistic regression model.\n",
    "\n",
    "To calculate the accuracy of the logistic regression model's predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a76c8878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9445564882444857"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e9d0e",
   "metadata": {},
   "source": [
    "To assess precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34e548ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733968401486989"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ba1cc",
   "metadata": {},
   "source": [
    "To calculate the recall score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d0b3aaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9140228714797375"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69252519",
   "metadata": {},
   "source": [
    "Now, we can compute the F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e87e7f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9427759702206262"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f3baf",
   "metadata": {},
   "source": [
    "Indeed, the values for accuracy, precision, recall, and F1 score are notably higher after applying SMOTE oversampling. This improvement demonstrates the effectiveness of addressing class imbalance with oversampling techniques like SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7550e77",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c0ea3d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0a48a",
   "metadata": {},
   "source": [
    "The 'decision_tree_model' is now successfully trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d399e",
   "metadata": {},
   "source": [
    "Let's make predictions on the test set using the Decision Tree Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "babda7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4af1e1",
   "metadata": {},
   "source": [
    "The `y_pred2` variable contains the predictions made by the Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd92e6",
   "metadata": {},
   "source": [
    "To calculate accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eb986d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9982012427777173"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76753112",
   "metadata": {},
   "source": [
    "Let's assess precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2d37f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974584732685849"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7aad9",
   "metadata": {},
   "source": [
    "To calculate the recall score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "250f2eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989455120629784"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65409b96",
   "metadata": {},
   "source": [
    "Now, let's compute the F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a96ddd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998201438848921"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726462e",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "To use the Random Forest Classifier, we begin by training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7cf9e69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b6e7f7",
   "metadata": {},
   "source": [
    "The 'random_forest_model' is now successfully trained. Please note that the dataset has become larger after oversampling, which may lead to longer training times.\n",
    "Now, let's make predictions on the test set using the Random Forest Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "636b58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f3460",
   "metadata": {},
   "source": [
    "The `y_pred3` variable contains the predictions made by the Random Forest Classifier.\n",
    "To calculate accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "648b1dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999364075729495"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a463b6",
   "metadata": {},
   "source": [
    "Let's assess precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "54dc7680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998727504090166"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d9369",
   "metadata": {},
   "source": [
    "To calculate the recall score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b7e9d917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0006a",
   "metadata": {},
   "source": [
    "Now, let's compute the F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "20cdf8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999363711561361"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a97d9c",
   "metadata": {},
   "source": [
    "To visualize the results, we have created a dataframe containing the models and their accuracy scores, and then used a bar plot to display the information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92bfd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame({'Models': ['LR', 'DT', 'RF'], 'ACC': [accuracy_score(y_test, y_pred1) * 100, accuracy_score(y_test, y_pred2) * 100, accuracy_score(y_test, y_pred3) * 100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "67afba35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>94.455649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>99.820124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>99.993641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Models        ACC\n",
       "0     LR  94.455649\n",
       "1     DT  99.820124\n",
       "2     RF  99.993641"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a06ac92",
   "metadata": {},
   "source": [
    "Now, let's visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a2abca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Models', ylabel='ACC'>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=final_data['Models'], y=final_data['ACC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c12fe3",
   "metadata": {},
   "source": [
    "As shown in the bar plot, it's evident that the Random Forest Classifier is the best model for this dataset after oversampling.\n",
    "\n",
    "## Saving the Best Random Forest Classifier Model\n",
    "\n",
    "In this section, we will save our best model, the Random Forest Classifier. After oversampling the dataset using SMOTE, training the model is a time-consuming process. To save time in the future and avoid retraining, we will save the model so that we can perform predictions using the saved model.\n",
    "\n",
    "### Why Save the Model?\n",
    "\n",
    "Saving the model is essential when the training process is time-consuming and resource-intensive. By saving the model, we can quickly make predictions without the need to train the model repeatedly.\n",
    "\n",
    "### Training on the Entire Dataset\n",
    "\n",
    "In production, we want our model to perform well on real-world data. Therefore, we will train our best model on the entire dataset after oversampling. This ensures that the model is trained on a balanced dataset for better generalization.\n",
    "\n",
    "To do this, we will create an instance of our best model, the Random Forest Classifier, and train it on the entire dataset after SMOTE. The independent variables are available inside `X_res`, and the dependent variable 'Class' is available inside `y_res`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b50ccad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier()\n",
    "rf1.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201158a",
   "metadata": {},
   "source": [
    "With this step, our Random Forest Classifier will be trained on the complete, balanced dataset, making it ready for use in production scenarios.\n",
    "\n",
    "Now, let's save our trained model so that we can use it for future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a47470ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "91725263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['credit_card_model']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf1, \"credit_card_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c279c933",
   "metadata": {},
   "source": [
    "With this code, the model is successfully saved under the name \"credit_card_model.\"\n",
    "\n",
    "In the future, you can load the saved model and use it for predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "358e8a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transaction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"credit_card_model\")\n",
    "\n",
    "sample_input = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "prediction = model.predict([sample_input])\n",
    "\n",
    "if prediction == 0:\n",
    "    print(\"Normal Transaction\")\n",
    "else:\n",
    "    print(\"Fraudulent Transaction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0590e615",
   "metadata": {},
   "source": [
    "In this example, we load the saved model, provide a sample input for prediction, and check whether it's a normal or fraudulent transaction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
